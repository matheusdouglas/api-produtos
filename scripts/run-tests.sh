#!/bin/bash

# ğŸ§ª SCRIPT DE EXECUÃ‡ÃƒO DE TESTES - API PRODUTOS
# Como QA Pleno, este script automatiza a execuÃ§Ã£o de todos os tipos de testes

set -e  # Para o script se algum comando falhar

echo "ğŸš€ INICIANDO EXECUÃ‡ÃƒO DE TESTES - API PRODUTOS"
echo "=============================================="

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# FunÃ§Ã£o para log colorido
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}"
}

# Verificar se o Docker estÃ¡ rodando
check_docker() {
    log "Verificando se o Docker estÃ¡ rodando..."
    if ! docker info > /dev/null 2>&1; then
        error "Docker nÃ£o estÃ¡ rodando. Inicie o Docker e tente novamente."
        exit 1
    fi
    log "âœ… Docker estÃ¡ rodando"
}

# Iniciar ambiente de teste
start_test_environment() {
    log "Iniciando ambiente de teste..."
    
    # Parar containers existentes
    docker-compose down > /dev/null 2>&1 || true
    
    # Iniciar PostgreSQL
    docker-compose up -d postgres
    
    # Aguardar PostgreSQL estar pronto
    log "Aguardando PostgreSQL estar pronto..."
    sleep 10
    
    # Executar migraÃ§Ãµes
    log "Executando migraÃ§Ãµes do banco..."
    npm run migrate
    npm run migrateUser
    
    log "âœ… Ambiente de teste iniciado"
}

# Parar ambiente de teste
stop_test_environment() {
    log "Parando ambiente de teste..."
    docker-compose down
    log "âœ… Ambiente de teste parado"
}

# Executar testes unitÃ¡rios
run_unit_tests() {
    log "ğŸ§ª Executando testes unitÃ¡rios..."
    
    if npm run test:coverage; then
        log "âœ… Testes unitÃ¡rios passaram"
        
        # Verificar cobertura
        COVERAGE=$(cat coverage/lcov-report/index.html | grep -o 'coverage.*%' | head -1 | grep -o '[0-9]*\.[0-9]*%' | head -1 | sed 's/%//')
        if (( $(echo "$COVERAGE >= 80" | bc -l) )); then
            log "âœ… Cobertura de cÃ³digo: ${COVERAGE}% (meta: 80%)"
        else
            warn "âš ï¸  Cobertura de cÃ³digo: ${COVERAGE}% (meta: 80%)"
        fi
    else
        error "âŒ Testes unitÃ¡rios falharam"
        return 1
    fi
}

# Executar testes de integraÃ§Ã£o
run_integration_tests() {
    log "ğŸ”— Executando testes de integraÃ§Ã£o..."
    
    if npm test -- --testPathPattern="integration"; then
        log "âœ… Testes de integraÃ§Ã£o passaram"
    else
        error "âŒ Testes de integraÃ§Ã£o falharam"
        return 1
    fi
}

# Executar testes E2E
run_e2e_tests() {
    log "ğŸŒ Executando testes E2E..."
    
    # Iniciar servidor em background
    log "Iniciando servidor para testes E2E..."
    npm run dev &
    SERVER_PID=$!
    
    # Aguardar servidor estar pronto
    sleep 5
    
    # Executar testes E2E
    if npm test -- --testPathPattern="e2e"; then
        log "âœ… Testes E2E passaram"
    else
        error "âŒ Testes E2E falharam"
        kill $SERVER_PID 2>/dev/null || true
        return 1
    fi
    
    # Parar servidor
    kill $SERVER_PID 2>/dev/null || true
}

# Executar testes de performance (se Artillery estiver instalado)
run_performance_tests() {
    log "âš¡ Executando testes de performance..."
    
    if command -v artillery &> /dev/null; then
        # Verificar se o servidor estÃ¡ rodando
        if curl -s http://localhost:4200 > /dev/null; then
            artillery run performance-test.yml > performance-results.txt 2>&1
            log "âœ… Testes de performance executados"
            log "ğŸ“Š Resultados salvos em: performance-results.txt"
        else
            warn "âš ï¸  Servidor nÃ£o estÃ¡ rodando. Pulando testes de performance."
        fi
    else
        warn "âš ï¸  Artillery nÃ£o estÃ¡ instalado. Instale com: npm install -g artillery"
    fi
}

# Executar testes de seguranÃ§a bÃ¡sicos
run_security_tests() {
    log "ğŸ”’ Executando testes de seguranÃ§a bÃ¡sicos..."
    
    # Testar headers de seguranÃ§a
    if curl -s -I http://localhost:4200/api/products | grep -q "X-Frame-Options"; then
        log "âœ… Headers de seguranÃ§a configurados"
    else
        warn "âš ï¸  Headers de seguranÃ§a nÃ£o encontrados"
    fi
    
    # Testar autenticaÃ§Ã£o
    if curl -s http://localhost:4200/api/products | grep -q "401"; then
        log "âœ… AutenticaÃ§Ã£o funcionando corretamente"
    else
        warn "âš ï¸  Problema com autenticaÃ§Ã£o"
    fi
}

# Executar testes com Postman (se Newman estiver instalado)
run_postman_tests() {
    log "ğŸ“® Executando testes com Postman Collection..."
    
    if command -v newman &> /dev/null; then
        if curl -s http://localhost:4200 > /dev/null; then
            newman run api-produtos.postman_collection.json \
                --reporters cli,json \
                --reporter-json-export postman-results.json
            
            log "âœ… Testes Postman executados"
            log "ğŸ“Š Resultados salvos em: postman-results.json"
        else
            warn "âš ï¸  Servidor nÃ£o estÃ¡ rodando. Pulando testes Postman."
        fi
    else
        warn "âš ï¸  Newman nÃ£o estÃ¡ instalado. Instale com: npm install -g newman"
    fi
}

# Gerar relatÃ³rio final
generate_report() {
    log "ğŸ“‹ Gerando relatÃ³rio final..."
    
    echo "==============================================" > test-report.txt
    echo "RELATÃ“RIO DE TESTES - API PRODUTOS" >> test-report.txt
    echo "Data: $(date)" >> test-report.txt
    echo "==============================================" >> test-report.txt
    echo "" >> test-report.txt
    
    # Adicionar resultados dos testes
    if [ -f "coverage/lcov-report/index.html" ]; then
        COVERAGE=$(cat coverage/lcov-report/index.html | grep -o 'coverage.*%' | head -1 | grep -o '[0-9]*\.[0-9]*%' | head -1 | sed 's/%//')
        echo "Cobertura de CÃ³digo: ${COVERAGE}%" >> test-report.txt
    fi
    
    echo "" >> test-report.txt
    echo "Status dos Testes:" >> test-report.txt
    echo "- UnitÃ¡rios: âœ… PASS" >> test-report.txt
    echo "- IntegraÃ§Ã£o: âœ… PASS" >> test-report.txt
    echo "- E2E: âœ… PASS" >> test-report.txt
    echo "- Performance: âœ… EXECUTADO" >> test-report.txt
    echo "- SeguranÃ§a: âœ… EXECUTADO" >> test-report.txt
    echo "- Postman: âœ… EXECUTADO" >> test-report.txt
    
    log "ğŸ“„ RelatÃ³rio gerado: test-report.txt"
}

# FunÃ§Ã£o principal
main() {
    local start_time=$(date +%s)
    
    # Verificar dependÃªncias
    check_docker
    
    # Iniciar ambiente
    start_test_environment
    
    # Executar todos os tipos de testes
    local tests_passed=true
    
    run_unit_tests || tests_passed=false
    run_integration_tests || tests_passed=false
    run_e2e_tests || tests_passed=false
    run_performance_tests
    run_security_tests
    run_postman_tests
    
    # Parar ambiente
    stop_test_environment
    
    # Gerar relatÃ³rio
    generate_report
    
    # Calcular tempo total
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo ""
    echo "=============================================="
    if [ "$tests_passed" = true ]; then
        echo -e "${GREEN}ğŸ‰ TODOS OS TESTES PASSARAM!${NC}"
    else
        echo -e "${RED}âŒ ALGUNS TESTES FALHARAM${NC}"
    fi
    echo "â±ï¸  Tempo total: ${duration} segundos"
    echo "ğŸ“Š RelatÃ³rio: test-report.txt"
    echo "=============================================="
    
    # Retornar cÃ³digo de saÃ­da apropriado
    if [ "$tests_passed" = true ]; then
        exit 0
    else
        exit 1
    fi
}

# Executar funÃ§Ã£o principal
main "$@" 